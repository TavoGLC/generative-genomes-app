import Link from "next/link"

export const MainHow = () => {
    return (
        <div className="felx p-5 ">
            <p className="text-xl sm:text-3xl space-y-3"> How the forecast is made.</p>

            <p>
                Genome forecasting relies on a variational autoencoder network, a special kind of neural network architecture used 
                for generative AI. An autoencoder is the combination of two networks an encoder and a decoder. The encoder compresses 
                the information resulting in a 2D space that encodes the necessary information to reconstruct it. While the decoder 
                performs the information reconstruction. Each forecast is performed by a unique decoder network trained with genomes 
                of the same virus except for influenza. The hemagglutinin and neuraminidase genes for each type of influenza virus 
                were combined into a single model for each gene. 
                <p><br/></p>
                In free mode the reconstruction is made by providing a set of random numbers to the network, this will generate a single 
                genome. A series of variants can be generated by modifying the slider values. In the case of the SARS Cov2 genome, a second 
                mode is added where a second network transforms a series of temporal variables into the 2D learned space. This allows us to 
                partially approximate the temporal behavior of the genome as well as possible future variants. 
                <p><br/></p>
                As with any generative AI model it can hallucinate unlikely genomes, this is most likely to happen in the free mode. One simple 
                way to reduce the likelihood of a hallucination is by looking at the first three letters of the forecasted genome. If the first 
                three letters are other than ATG then the genome is most likely a hallucination. The identity and precision of the forecast can 
                also be evaluated by performing a BLAST analysis from the resulting sequence
            </p>
            <p><br/></p>
            <p>
                Specifics of how such models are trained can be found in 
                <Link href="https://github.com/TavoGLC/generative-genomes"  target="_blank" rel="noopener noreferrer"> here, </Link>
                while an example of how to implement and train the SARSCov2 model can be found 
                <Link href="https://www.kaggle.com/code/tavoglc/sars-cov-2-genome-prediction-with-vaes"  target="_blank" rel="noopener noreferrer"> here. </Link>
                The trained model can be found 
                <Link href="https://www.kaggle.com/models/tavoglc/sars-cov2-full-genome-prediction-with-vaes"  target="_blank" rel="noopener noreferrer"> here </Link>
                and an example of how to interpolate from the learned representation to the full genome can be found 
                <Link href="https://www.kaggle.com/code/tavoglc/visualizing-and-interpolating-the-latent-space"  target="_blank" rel="noopener noreferrer"> here. </Link>
                A comprehensive computational review of SARS-COV2 adaptation can be found 
                <Link href="https://www.kaggle.com/code/tavoglc/a-computational-description-of-sarscov2-adaptation"  target="_blank" rel="noopener noreferrer"> here. </Link>
            </p>
            
        </div>
    )
}